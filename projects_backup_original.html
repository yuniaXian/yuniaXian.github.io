<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Participated Projects</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600,700&display=swap" rel="stylesheet">
        <style>
        
        body {
            font-family: 'Open Sans', sans-serif;
        }
        </style>
    </head>
    <body class="bg-white text-gray-900">
        <div class="container mx-auto px-4">
            <header class="flex justify-between items-center py-6">
                <h1 class="text-3xl font-bold">Home</h1>
                <nav>
                  <ul class="flex space-x-4 text-lg">
                    <li><a href="index.html" class="text-gray-900 hover:text-gray-700">Home</a></li>
                    <li><a href="#" class="text-gray-900 hover:text-gray-700">Projects</a></li>
                    <li><a href="publications.html" class="text-gray-900 hover:text-gray-700">Publications</a></li>
                    <li><a href="awards.html" class="text-gray-900 hover:text-gray-700">Honors & Awards</a></li>
                  </ul>
                </nav>
            </header>
            <main>
                <h2 class="text-2xl font-bold py-6">Projects</h2>
                <div class="space-y-12">
                    <!-- Project 1 -->
                    <div>
                    <h3 class="text-xl font-semibold mb-2">Knowledge graph based intents reconstruction</h3>
                    <img src="projects/kg_intents/KG_intents01.png" alt="KG intents project class" width="500" height="200" class="mb-4">
                    <p> Built service knowledge graph (KG). Re-construction of label hierarchy and refining classification logistics.
                        Labels are reselected and redefined by entity and sementic similarity. The knowledge graph based intents improve classification model
                        accuracy from 82.48% to 92.17%. The knowledge graph is also used to ingest fine grain factual knowledge in contextual learning and helps to surpress hallucination in generation.
                    </p>
                    </div>
                    <!-- Project 2 -->
                    <div>
                    <h3 class="text-xl font-semibold mb-2">LLMs augmented Auto-labelling pipeline</h3>
                    <img src="projects/auto_label/auto_label.png" alt="auto labelling project Thumbnail" width="500" height="200" class="mb-4">
                    <p>This project is to conduct autolabelling in text data for text classification. The pipeline utilizes a diversity filtering algorithm to draw diverse and comprehensive samples from given labelled data. 
                        By contextual learning, it leverages LLM to summerize and formalize the definition of each label (or labelling guidelines). With delibrated designed prompts integrated by definitions, the pipeline auto label data samples.  </p>
                    </div>
                    <!-- Project 3 -->
                    <div>
                    <h3 class="text-xl font-semibold mb-2">Knowledge graph to text modelling</h3>
                    <img src="projects/kg2text/Kg2text_paper.png" alt="PixelTone Project Thumbnail" width="500" height="200" class="mb-4">
                    <p> Converting knowledge graph triples to text (simplied as kg2text) is a classic NLP task. This project re-shaped the task as a tranlsation task and utilizes the language-agnostic representation learned by multilingual
                        language model to conduct this task. The model was extendly pretrained and fine-tuned from a mbart 50 model. This project was finished during internship in Amazon
                    </p>
                    </div>
                </div>
            </main>
        </div>
    </body>
</html>